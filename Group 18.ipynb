{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           DATE   TIME  LONGITUDE  LATITUDE     DESCRIPTION\n",
      "0    21/01/2026  10:02   4.155096  9.297234    FHS Entrance\n",
      "1    21/01/2026  10:04   4.155096  9.297513    FHS Entrance\n",
      "2   21/01/2026   10:05   4.155121  9.297781    FHS Entrance\n",
      "3    21/01/2026  10:06   4.155138  9.298028    FHS Entrance\n",
      "4    21/01/2026  10:07   4.155112  9.298239    FHS Entrance\n",
      "..          ...    ...        ...       ...             ...\n",
      "79   21/01/2026  11:00   4.161425  9.283848  Baptist Church\n",
      "80   21/01/2026  11:00   4.161698  9.283796     Huib Street\n",
      "81   21/01/2026  11:01   4.161938  9.283808     Huib Street\n",
      "82   21/01/2026  11:01   4.162183  9.283690     Huib Street\n",
      "83   21/01/2026  11:02   4.162429  9.283591   HUIB Campus B\n",
      "\n",
      "[84 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset=pd.read_csv('Book1.csv')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          DATE   TIME  LONGITUDE  LATITUDE          DESCRIPTION\n",
      "0   21/01/2026  10:02   4.155118  9.298021         FHS Entrance\n",
      "5   21/01/2026  10:08   4.155572  9.298822            Ms Bright\n",
      "8   21/01/2026  10:12   4.156334  9.298715      Parkline agency\n",
      "9   21/01/2026  10:13   4.157088  9.298511             Mille 18\n",
      "10  21/01/2026  10:14   4.157297  9.298505             Mille 19\n",
      "11  21/01/2026  10:15   4.157830  9.298376             Mille 20\n",
      "12  21/01/2026  10:16   4.158468  9.298253    Mille 18 Junction\n",
      "15  21/01/2026  10:18   4.159489  9.298099               School\n",
      "17  21/01/2026  10:20   4.160711  9.297967  Landmark university\n",
      "19  21/01/2026  10:21   4.161131  9.297978     Landmark juction\n",
      "22  21/01/2026  10:23   4.161555  9.297433        Hims Junction\n",
      "26  21/01/2026  10:25   4.160958  9.295032       Hims unversity\n",
      "34  21/01/2026  10:29   4.160021  9.284605         Mayor street\n",
      "63  21/01/2026  10:49   4.160314  9.285853       Premier league\n",
      "75  21/01/2026  10:57   4.159980  9.284141        Health center\n",
      "76  21/01/2026  10:58   4.161060  9.283942       Baptist Church\n",
      "80  21/01/2026  11:00   4.162000  9.283746          Huib Street\n",
      "83  21/01/2026  11:02   4.162429  9.283591        HUIB Campus B\n"
     ]
    }
   ],
   "source": [
    "search_graph={\n",
    "    \n",
    "}\n",
    "i=0\n",
    "while i<len(dataset):\n",
    "    j=i+1\n",
    "    while j<len(dataset):\n",
    "        if dataset.iloc[i,-1]==dataset.iloc[j,-1]:\n",
    "            dataset.iloc[i,2]=((dataset.iloc[i,2]+dataset.iloc[j,2])/2)\n",
    "            dataset.iloc[i,3]=((dataset.iloc[i,3]+dataset.iloc[j,3])/2)\n",
    "            dataset.drop(dataset.index[j],inplace=True)\n",
    "        else:\n",
    "            j+=1\n",
    "    i+=1\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset:\n",
      "            DATE   TIME  LONGITUDE  LATITUDE     DESCRIPTION\n",
      "0    21/01/2026  10:02   4.155096  9.297234    FHS Entrance\n",
      "1    21/01/2026  10:04   4.155096  9.297513    FHS Entrance\n",
      "2   21/01/2026   10:05   4.155121  9.297781    FHS Entrance\n",
      "3    21/01/2026  10:06   4.155138  9.298028    FHS Entrance\n",
      "4    21/01/2026  10:07   4.155112  9.298239    FHS Entrance\n",
      "..          ...    ...        ...       ...             ...\n",
      "79   21/01/2026  11:00   4.161425  9.283848  Baptist Church\n",
      "80   21/01/2026  11:00   4.161698  9.283796     Huib Street\n",
      "81   21/01/2026  11:01   4.161938  9.283808     Huib Street\n",
      "82   21/01/2026  11:01   4.162183  9.283690     Huib Street\n",
      "83   21/01/2026  11:02   4.162429  9.283591   HUIB Campus B\n",
      "\n",
      "[84 rows x 5 columns]\n",
      "Cleaned dataset:\n",
      "           DATE   TIME  LONGITUDE  LATITUDE          DESCRIPTION\n",
      "0   21/01/2026  10:02   4.155118  9.298021         FHS Entrance\n",
      "1   21/01/2026  10:08   4.155572  9.298822            Ms Bright\n",
      "2   21/01/2026  10:12   4.156334  9.298715      Parkline agency\n",
      "3   21/01/2026  10:13   4.157088  9.298511             Mille 18\n",
      "4   21/01/2026  10:14   4.157297  9.298505             Mille 19\n",
      "5   21/01/2026  10:15   4.157830  9.298376             Mille 20\n",
      "6   21/01/2026  10:16   4.158468  9.298253    Mille 18 Junction\n",
      "7   21/01/2026  10:18   4.159489  9.298099               School\n",
      "8   21/01/2026  10:20   4.160711  9.297967  Landmark university\n",
      "9   21/01/2026  10:21   4.161131  9.297978     Landmark juction\n",
      "10  21/01/2026  10:23   4.161555  9.297433        Hims Junction\n",
      "11  21/01/2026  10:25   4.160958  9.295032       Hims unversity\n",
      "12  21/01/2026  10:29   4.160021  9.284605         Mayor street\n",
      "13  21/01/2026  10:49   4.160314  9.285853       Premier league\n",
      "14  21/01/2026  10:57   4.159980  9.284141        Health center\n",
      "15  21/01/2026  10:58   4.161060  9.283942       Baptist Church\n",
      "16  21/01/2026  11:00   4.162000  9.283746          Huib Street\n",
      "17  21/01/2026  11:02   4.162429  9.283591        HUIB Campus B\n"
     ]
    }
   ],
   "source": [
    "from haversine import haversine\n",
    "\n",
    "# Step 1: Load dataset\n",
    "dataset = pd.read_csv('Book1.csv')\n",
    "print(\"Original dataset:\\n\", dataset)\n",
    "\n",
    "# Step 2: Merge duplicates based on the last column\n",
    "i = 0\n",
    "while i < len(dataset):\n",
    "    j = i + 1\n",
    "    while j < len(dataset):\n",
    "        if dataset.iloc[i, -1] == dataset.iloc[j, -1]:\n",
    "            # Average coordinates\n",
    "            dataset.iloc[i, 2] = (dataset.iloc[i, 2] + dataset.iloc[j, 2]) / 2\n",
    "            dataset.iloc[i, 3] = (dataset.iloc[i, 3] + dataset.iloc[j, 3]) / 2\n",
    "            dataset.drop(dataset.index[j], inplace=True)\n",
    "            dataset.reset_index(drop=True, inplace=True)  # keep indices consistent\n",
    "        else:\n",
    "            j += 1\n",
    "    i += 1\n",
    "\n",
    "print(\"Cleaned dataset:\\n\", dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compute pairwise distances\n",
    "distance = []\n",
    "for i in range(len(dataset)):\n",
    "    for j in range(i+1, len(dataset)):\n",
    "        c1 = (dataset.iloc[i, 3], dataset.iloc[i, 2])  # (lat, lon)\n",
    "        c2 = (dataset.iloc[j, 3], dataset.iloc[j, 2])\n",
    "        distance.append(haversine(c1, c2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Graph:\n",
      " {'FHS Entrance': [0.10212952197849294, 4.155117625000001, 9.298020812499999, '21/01/2026', '10:02', 'FHS Entrance'], 'Ms Bright': [0.1541902436200774, 4.1555722500000005, 9.29882225, '21/01/2026', '10:08', 'Ms Bright'], 'Parkline agency': [0.22298169666803033, 4.156333999999999, 9.298715, '21/01/2026', '10:12', 'Parkline agency'], 'Mille 18': [0.24513704594784128, 4.157088, 9.298511, '21/01/2026', '10:13', 'Mille 18'], 'Mille 19': [0.30024888782415426, 4.157297, 9.298505, '21/01/2026', '10:14', 'Mille 19'], 'Mille 20': [0.3685557530427666, 4.157830000000001, 9.298376, '21/01/2026', '10:15', 'Mille 20'], 'Mille 18 Junction': [0.47971387385620207, 4.158468, 9.298252999999999, '21/01/2026', '10:16', 'Mille 18 Junction'], 'School': [0.613758984349267, 4.1594885, 9.2980995, '21/01/2026', '10:18', 'School'], 'Landmark university': [0.6599447004103072, 4.1607105, 9.297966500000001, '21/01/2026', '10:20', 'Landmark university'], 'Landmark juction': [0.7093767653386919, 4.1611315, 9.29797775, '21/01/2026', '10:21', 'Landmark juction'], 'Hims Junction': [0.7218930000467785, 4.161554625000001, 9.297433, '21/01/2026', '10:23', 'Hims Junction'], 'Hims unversity': [1.5858960950425707, 4.160957640625, 9.295032164062501, '21/01/2026', '10:25', 'Hims unversity'], 'Mayor street': [1.468293717761024, 4.160021268799168, 9.284604631766175, '21/01/2026', '10:29', 'Mayor street'], 'Premier league': [1.6329996487371556, 4.160313703125, 9.2858525, '21/01/2026', '10:49', 'Premier league'], 'Health center': [1.6959085047542, 4.15998, 9.284141, '21/01/2026', '10:57', 'Health center'], 'Baptist Church': [1.7578301056587287, 4.1610601250000006, 9.28394175, '21/01/2026', '10:58', 'Baptist Church'], 'Huib Street': [1.7939401673962445, 4.1620004999999995, 9.283746, '21/01/2026', '11:00', 'Huib Street'], 'HUIB Campus B': [0.08443621471597114, 4.162429, 9.283591, '21/01/2026', '11:02', 'HUIB Campus B']}\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Build search_graph\n",
    "search_graph = {}\n",
    "for i in range(len(dataset)):\n",
    "    search_graph[dataset.iloc[i, 4]] = [\n",
    "        distance[i] if i < len(distance) else None,  # safe indexing\n",
    "        dataset.iloc[i, 2],  # longitude\n",
    "        dataset.iloc[i, 3],  # latitude\n",
    "        dataset.iloc[i, 0],  # other info\n",
    "        dataset.iloc[i, 1],\n",
    "        dataset.iloc[i, 4]   # key\n",
    "    ]\n",
    "print(\"Search Graph:\\n\", search_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Graph:\n",
      "FHS Entrance : ([0.10212952197849294, 4.155117625000001, 9.298020812499999, '21/01/2026', '10:02', 'FHS Entrance'], [0.1541902436200774, 4.1555722500000005, 9.29882225, '21/01/2026', '10:08', 'Ms Bright'])\n",
      "Ms Bright : ([0.1541902436200774, 4.1555722500000005, 9.29882225, '21/01/2026', '10:08', 'Ms Bright'], [0.22298169666803033, 4.156333999999999, 9.298715, '21/01/2026', '10:12', 'Parkline agency'])\n",
      "Parkline agency : ([0.22298169666803033, 4.156333999999999, 9.298715, '21/01/2026', '10:12', 'Parkline agency'], [0.24513704594784128, 4.157088, 9.298511, '21/01/2026', '10:13', 'Mille 18'])\n",
      "Mille 18 : ([0.24513704594784128, 4.157088, 9.298511, '21/01/2026', '10:13', 'Mille 18'], [0.30024888782415426, 4.157297, 9.298505, '21/01/2026', '10:14', 'Mille 19'])\n",
      "Mille 19 : ([0.30024888782415426, 4.157297, 9.298505, '21/01/2026', '10:14', 'Mille 19'], [0.3685557530427666, 4.157830000000001, 9.298376, '21/01/2026', '10:15', 'Mille 20'])\n",
      "Mille 20 : ([0.3685557530427666, 4.157830000000001, 9.298376, '21/01/2026', '10:15', 'Mille 20'], [0.47971387385620207, 4.158468, 9.298252999999999, '21/01/2026', '10:16', 'Mille 18 Junction'])\n",
      "Mille 18 Junction : ([0.47971387385620207, 4.158468, 9.298252999999999, '21/01/2026', '10:16', 'Mille 18 Junction'], [0.613758984349267, 4.1594885, 9.2980995, '21/01/2026', '10:18', 'School'])\n",
      "School : ([0.613758984349267, 4.1594885, 9.2980995, '21/01/2026', '10:18', 'School'], [0.6599447004103072, 4.1607105, 9.297966500000001, '21/01/2026', '10:20', 'Landmark university'])\n",
      "Landmark university : ([0.6599447004103072, 4.1607105, 9.297966500000001, '21/01/2026', '10:20', 'Landmark university'], [0.7093767653386919, 4.1611315, 9.29797775, '21/01/2026', '10:21', 'Landmark juction'])\n",
      "Landmark juction : ([0.7093767653386919, 4.1611315, 9.29797775, '21/01/2026', '10:21', 'Landmark juction'], [0.7218930000467785, 4.161554625000001, 9.297433, '21/01/2026', '10:23', 'Hims Junction'])\n",
      "Hims Junction : ([0.7218930000467785, 4.161554625000001, 9.297433, '21/01/2026', '10:23', 'Hims Junction'], [1.5858960950425707, 4.160957640625, 9.295032164062501, '21/01/2026', '10:25', 'Hims unversity'])\n",
      "Hims unversity : ([1.5858960950425707, 4.160957640625, 9.295032164062501, '21/01/2026', '10:25', 'Hims unversity'], [1.468293717761024, 4.160021268799168, 9.284604631766175, '21/01/2026', '10:29', 'Mayor street'])\n",
      "Mayor street : ([1.468293717761024, 4.160021268799168, 9.284604631766175, '21/01/2026', '10:29', 'Mayor street'], [1.6329996487371556, 4.160313703125, 9.2858525, '21/01/2026', '10:49', 'Premier league'])\n",
      "Premier league : ([1.6329996487371556, 4.160313703125, 9.2858525, '21/01/2026', '10:49', 'Premier league'], [1.6959085047542, 4.15998, 9.284141, '21/01/2026', '10:57', 'Health center'])\n",
      "Health center : ([1.6959085047542, 4.15998, 9.284141, '21/01/2026', '10:57', 'Health center'], [1.7578301056587287, 4.1610601250000006, 9.28394175, '21/01/2026', '10:58', 'Baptist Church'])\n",
      "Baptist Church : ([1.7578301056587287, 4.1610601250000006, 9.28394175, '21/01/2026', '10:58', 'Baptist Church'], [1.7939401673962445, 4.1620004999999995, 9.283746, '21/01/2026', '11:00', 'Huib Street'])\n",
      "Huib Street : ([1.7939401673962445, 4.1620004999999995, 9.283746, '21/01/2026', '11:00', 'Huib Street'], [0.08443621471597114, 4.162429, 9.283591, '21/01/2026', '11:02', 'HUIB Campus B'])\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Build new_graph (pairwise connections)\n",
    "new_graph = {}\n",
    "for i in range(len(dataset)-1):\n",
    "    new_graph[dataset.iloc[i, 4]] = (\n",
    "        search_graph[dataset.iloc[i, 4]],\n",
    "        search_graph[dataset.iloc[i+1, 4]]\n",
    "    )\n",
    "\n",
    "print(\"New Graph:\")\n",
    "for key, value in new_graph.items():\n",
    "    print(key, \":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
